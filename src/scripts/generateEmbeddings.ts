import OpenAI from 'openai';
import { createClient } from '@supabase/supabase-js';
import { aggregateKnowledgeBase } from './aggregateKnowledgeBase';
import type { KnowledgeChunk } from './aggregateKnowledgeBase';
import dotenv from 'dotenv';

dotenv.config();

const supabaseUrl = process.env.VITE_SUPABASE_URL!;
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.VITE_SUPABASE_ANON_KEY!;
const supabase = createClient(supabaseUrl, supabaseKey);

const openai = new OpenAI({
  apiKey: process.env.VITE_OPENAI_API_KEY || process.env.OPENAI_API_KEY,
});

async function generateEmbedding(text: string): Promise<number[]> {
  try {
    const response = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: text,
    });
    return response.data[0].embedding;
  } catch (error) {
    console.error('Error generating embedding:', error);
    throw error;
  }
}

async function clearKnowledgeBase() {
  console.log('ğŸ—‘ï¸  Clearing existing knowledge base...');
  const { error } = await supabase
    .from('knowledge_base')
    .delete()
    .neq('id', '00000000-0000-0000-0000-000000000000');
  
  if (error) {
    console.error('Error clearing knowledge base:', error);
    throw error;
  }
  console.log('âœ… Knowledge base cleared');
}

async function insertKnowledgeChunk(chunk: KnowledgeChunk, embedding: number[]) {
  // Insert embedding as JSON array - Supabase will handle the conversion to vector type
  const { error } = await supabase
    .from('knowledge_base')
    .insert({
      content: chunk.content,
      metadata: chunk.metadata,
      embedding: JSON.stringify(embedding),
    });

  if (error) {
    console.error('Error inserting chunk:', error);
    throw error;
  }
}

async function generateAndStoreEmbeddings() {
  try {
    console.log('ğŸš€ Starting embedding generation process...\n');

    console.log('ğŸ“š Step 1: Aggregating knowledge base...');
    const chunks = await aggregateKnowledgeBase();
    console.log(`âœ… Aggregated ${chunks.length} chunks\n`);

    console.log('ğŸ—‘ï¸  Step 2: Clearing existing embeddings...');
    await clearKnowledgeBase();
    console.log('');

    console.log('ğŸ”® Step 3: Generating and storing embeddings...');
    let successCount = 0;
    let errorCount = 0;

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      try {
        console.log(`  Processing chunk ${i + 1}/${chunks.length}: ${chunk.metadata.type} - ${chunk.metadata.title || 'Untitled'}`);
        
        const embedding = await generateEmbedding(chunk.content);
        await insertKnowledgeChunk(chunk, embedding);
        
        successCount++;
        
        await new Promise(resolve => setTimeout(resolve, 100));
      } catch (error) {
        console.error(`  âŒ Error processing chunk ${i + 1}:`, error);
        errorCount++;
      }
    }

    console.log('\nâœ¨ Embedding generation complete!');
    console.log(`  âœ… Successfully processed: ${successCount} chunks`);
    if (errorCount > 0) {
      console.log(`  âŒ Failed: ${errorCount} chunks`);
    }
    console.log('\nğŸ‰ Knowledge base is ready for use!');

  } catch (error) {
    console.error('\nâŒ Fatal error during embedding generation:', error);
    throw error;
  }
}

// Run if this is the main module
if (import.meta.url === `file://${process.argv[1]}`) {
  generateAndStoreEmbeddings()
    .then(() => {
      console.log('\nâœ… All done! You can now use the AI assistant.');
      process.exit(0);
    })
    .catch((error) => {
      console.error('\nâŒ Failed to generate embeddings:', error);
      process.exit(1);
    });
}

export { generateAndStoreEmbeddings, generateEmbedding };
